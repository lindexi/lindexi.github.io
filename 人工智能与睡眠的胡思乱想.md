# 人工智能与睡眠的胡思乱想

这是我今天在散步过程的胡思乱想内容

<!--more-->
<!-- CreateTime:2025/08/19 07:18:16 -->

<!-- 发布 -->

故事的起因是，一天水哥和我说他在睡觉的时候念头十分复杂，那会缺少了记忆的读取，导致作出了很多奇怪的决策行为

我的核心胡思乱想是，如果人类真的有意识，则是否很类似于 GPT 一样。人类有一个内核思想，但是日常的行为会受到过往记忆的影响。在日常白天不睡觉的时候，人类的记忆是采用向量化存储的方式，这也能说明记忆钩子的重要性。此时的记忆还没被加入到人类的模型里面训练

晚上睡觉的时候，就可以开启缓慢的训练模式，将白天记忆的内容加入到训练里面，从而修改各种参数

今天早上看了一点人类神经内科的文档，感觉也许这个想法有点靠上了，虽然来说有点强行。那就继续打补丁，人类可能在 0-3 岁的时候，做的是比较大的参数调整。我这里依然还是用全联通图的思想，参数的调整是一个抽象的说法，即在全联通图里面，权重为 0 自然代表无连接。在10-15 岁的时候，做的是微调。此后，可能内核模型就很固定了，后续都是根据向量化搜记忆，加载上下文决定输出的行为，而很少微调模型参数了

如果人类也是如此的机制，那也就是说当前的模型训练工作方式是正确的朝着人类的智能路径发展的。人类在睡觉的时候，进行模型的增量训练。类似于当前的各种模型，实时重新训练存在以下问题：

- 模型的训练过程需要耗能耗时，实时性很难保证
- 训练结果不一定是正确的，必然需要进行重新校验的过程

根据以上问题可知，实时重新训练应该是不能适应日常生活的，否则可能会见到一堆喜怒无常的伪人。或者在远古狩猎过程中，前一秒准备干掉猎物，下一秒就开始爬树等是否奇怪的行为

睡觉的过程是一个非常好的时机，就如同系统升级一样，刚好有一段时间，不需要思考，那就刚好占用这个资源进行训练，训练之后进行校验，决定采用哪个训练结果或抛弃训练结果

歪个楼，也许起床气就这么来的。忽然被叫醒了，丢失了辛苦训练的数据，非常好气

以上就是胡思乱想的。看着玩就好了。但要真的人类的思维工作机制也是如此，那按照现在的模型训练方式，则可能真的就是走了人类思维的路。现在的模型训练方式：先收集数据，收集到的数据不立刻更改模型，模型保持稳定性且无记忆性，真需要上下文记忆，通过向量化搜数据库提供上下文，等待收集一波数据再进行重新训练或微调。这和我想象中的人类也是非常相同，人类内核是固执的，没有记忆的，表现有记忆只是各种上下文提供的信息而已，人类能否考虑周全，全靠记忆是否提供了全面的上下文信息